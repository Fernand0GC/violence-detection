import React, { useRef, useState, useEffect } from "react"
import * as tf from "@tensorflow/tfjs"
import { AlertTriangle, Download } from 'lucide-react'
import DetectionStats from './components/DetectionStats'
import TrafficLight from './components/TrafficLight'
import Charts from './components/Charts'
import './App.css'

const App = () => {
  const videoRef = useRef(null)
  const canvasRef = useRef(null)
  const ctxRef = useRef(null)
  const modelRef = useRef(null)
  const audioRef = useRef(null)
  const lastPhotoTime = useRef(0)
  const frameCount = useRef(0)

  // ============================================================
  // ‚öôÔ∏è CONFIGURACI√ìN DEL SISTEMA - MODIFICA AQU√ç
  // ============================================================
  const CONFIDENCE_THRESHOLD = 0.6  // 0.0 - 1.0 (0.6 = 60% confianza m√≠nima)
  const MIN_SIZE_PIXELS = 70         // Tama√±o m√≠nimo en p√≠xeles para detectar objetos
  const NMS_IOU_THRESHOLD = 0.5     // 0.0 - 1.0 (0.5 = eliminar duplicados con 50% overlap)

  const [isDetecting, setIsDetecting] = useState(false)
  const [status, setStatus] = useState("Esperando carga del modelo...")
  const [dangerLevel, setDangerLevel] = useState('safe')
  const [detections, setDetections] = useState([])
  const [totalKnives, setTotalKnives] = useState(0)
  const [totalGuns, setTotalGuns] = useState(0)
  const [showAlert, setShowAlert] = useState(false)
  const [detectionHistory, setDetectionHistory] = useState([])
  const [capturedPhotos, setCapturedPhotos] = useState([])
  const [autoSaveImages, setAutoSaveImages] = useState(true)

  // ============================================================
  // Inicializaci√≥n
  // ============================================================
  useEffect(() => {
    audioRef.current = new Audio('/alert.wav')
    audioRef.current.addEventListener('error', () => {
      console.warn('‚ö†Ô∏è No se encontr√≥ /alert.wav, usando beep')
    })
  }, [])

  // ============================================================
  // 1Ô∏è‚É£ Cargar el modelo YOLO11
  // ============================================================
  const loadModel = async () => {
    try {
      console.log("üì¶ Cargando modelo YOLO11 desde /model/model.json...")
      setStatus("Cargando modelo YOLO11...")

      const model = await tf.loadGraphModel("/model/model.json")
      modelRef.current = model

      console.log("‚úÖ Modelo YOLO11 cargado correctamente")
      console.log("üìã Inputs del modelo:", model.inputs)
      console.log("üìã Outputs del modelo:", model.outputs)
      setStatus("Modelo cargado ‚úÖ")
    } catch (error) {
      console.error("‚ùå Error al cargar el modelo:", error)
      setStatus("Error al cargar modelo ‚ùå")
    }
  }

  // ============================================================
  // 2Ô∏è‚É£ Iniciar c√°mara
  // ============================================================
  const startCamera = async () => {
    try {
      console.log("üìπ Solicitando acceso a la c√°mara...")
      const stream = await navigator.mediaDevices.getUserMedia({ video: true })
      videoRef.current.srcObject = stream

      videoRef.current.onloadedmetadata = () => {
        console.log("‚úÖ C√°mara obtenida:", stream.getVideoTracks()[0].label)
        console.log(
          "üì∫ Video metadata cargada",
          videoRef.current.videoWidth,
          "x",
          videoRef.current.videoHeight
        )
        canvasRef.current.width = videoRef.current.videoWidth
        canvasRef.current.height = videoRef.current.videoHeight
        ctxRef.current = canvasRef.current.getContext("2d")
      }

      await videoRef.current.play()
    } catch (error) {
      console.error("‚ùå Error al acceder a la c√°mara:", error)
    }
  }

  // ============================================================
  // 3Ô∏è‚É£ Decodificar salida YOLO11 ([1,6,8400] o [1,8400,6] para 2 clases)
  // ============================================================
  const decodeYOLOOutput = async (predictions, imgWidth, imgHeight, confThreshold = CONFIDENCE_THRESHOLD) => {
    const flat = await predictions.data()
    const shape = predictions.shape
    const [b, d1, d2] = shape

    if (frameCount.current === 1) {
      console.log("üìè Shape salida:", shape)
    }

    const detections = []
    let numAnchors, numAttrs

    // Formato: [1, 6, 8400] - x, y, w, h, conf_cuchillo, conf_pistola
    if (d1 === 6) {
      numAnchors = d2
      numAttrs = d1
      if (frameCount.current === 1) {
        console.log("‚úÖ Formato detectado: [1, 6, 8400] - 2 clases")
      }
      for (let i = 0; i < numAnchors; i++) {
        const x_center = flat[0 * numAnchors + i]
        const y_center = flat[1 * numAnchors + i]
        const width = flat[2 * numAnchors + i]
        const height = flat[3 * numAnchors + i]
        const conf_knife = flat[4 * numAnchors + i]
        const conf_gun = flat[5 * numAnchors + i]
        
        // Determinar clase con mayor confianza
        const maxConf = Math.max(conf_knife, conf_gun)
        if (maxConf < confThreshold) continue
        
        const classId = conf_knife > conf_gun ? 0 : 1
        const confidence = maxConf

        // üöÄ Coordenadas absolutas (0‚Äì640) ‚Üí escalar a canvas
        const scaleX = imgWidth / 640
        const scaleY = imgHeight / 640

        const x = (x_center - width / 2) * scaleX
        const y = (y_center - height / 2) * scaleY
        const w = width * scaleX
        const h = height * scaleY

        detections.push({ x, y, w, h, confidence, class: classId })
      }
    }
    // Formato: [1, 8400, 6]
    else if (d2 === 6) {
      numAnchors = d1
      numAttrs = d2
      if (frameCount.current === 1) {
        console.log("‚úÖ Formato detectado: [1, 8400, 6] - 2 clases")
      }
      for (let i = 0; i < numAnchors; i++) {
        const offset = i * numAttrs
        const x_center = flat[offset + 0]
        const y_center = flat[offset + 1]
        const width = flat[offset + 2]
        const height = flat[offset + 3]
        const conf_knife = flat[offset + 4]
        const conf_gun = flat[offset + 5]
        
        const maxConf = Math.max(conf_knife, conf_gun)
        if (maxConf < confThreshold) continue
        
        const classId = conf_knife > conf_gun ? 0 : 1
        const confidence = maxConf

        const scaleX = imgWidth / 640
        const scaleY = imgHeight / 640

        const x = (x_center - width / 2) * scaleX
        const y = (y_center - height / 2) * scaleY
        const w = width * scaleX
        const h = height * scaleY

        detections.push({ x, y, w, h, confidence, class: classId })
      }
    }
    // Formato antiguo: [1, 5, 8400] - solo una clase (cuchillos)
    else if (d1 === 5) {
      numAnchors = d2
      numAttrs = d1
      if (frameCount.current === 1) {
        console.log("‚úÖ Formato detectado: [1, 5, 8400] - 1 clase")
      }
      for (let i = 0; i < numAnchors; i++) {
        const x_center = flat[0 * numAnchors + i]
        const y_center = flat[1 * numAnchors + i]
        const width = flat[2 * numAnchors + i]
        const height = flat[3 * numAnchors + i]
        const conf = flat[4 * numAnchors + i]
        if (conf < confThreshold) continue

        const scaleX = imgWidth / 640
        const scaleY = imgHeight / 640

        const x = (x_center - width / 2) * scaleX
        const y = (y_center - height / 2) * scaleY
        const w = width * scaleX
        const h = height * scaleY

        detections.push({ x, y, w, h, confidence: conf, class: 0 })
      }
    } else if (d2 === 5) {
      numAnchors = d1
      numAttrs = d2
      if (frameCount.current === 1) {
        console.log("‚úÖ Formato detectado: [1, 8400, 5] - 1 clase")
      }
      for (let i = 0; i < numAnchors; i++) {
        const offset = i * numAttrs
        const x_center = flat[offset + 0]
        const y_center = flat[offset + 1]
        const width = flat[offset + 2]
        const height = flat[offset + 3]
        const conf = flat[offset + 4]
        if (conf < confThreshold) continue

        const scaleX = imgWidth / 640
        const scaleY = imgHeight / 640

        const x = (x_center - width / 2) * scaleX
        const y = (y_center - height / 2) * scaleY
        const w = width * scaleX
        const h = height * scaleY

        detections.push({ x, y, w, h, confidence: conf, class: 0 })
      }
    }

    if (frameCount.current === 1) {
      console.log(`üì¶ Detecciones decodificadas: ${detections.length}`)
      if (detections.length > 0) console.log("Ejemplo detecci√≥n:", detections[0])
    }
    return detections
  }

  // ============================================================
  // NMS - Non-Maximum Suppression
  // ============================================================
  const applyNMS = (detections, iouThreshold = NMS_IOU_THRESHOLD) => {
    if (detections.length === 0) return []

    detections.sort((a, b) => b.confidence - a.confidence)
    const finalDetections = []

    const calculateIoU = (boxA, boxB) => {
      const xA = Math.max(boxA.x, boxB.x)
      const yA = Math.max(boxA.y, boxB.y)
      const xB = Math.min(boxA.x + boxA.w, boxB.x + boxB.w)
      const yB = Math.min(boxA.y + boxA.h, boxB.y + boxB.h)

      const interWidth = Math.max(0, xB - xA)
      const interHeight = Math.max(0, yB - yA)
      const interArea = interWidth * interHeight

      const boxAArea = boxA.w * boxA.h
      const boxBArea = boxB.w * boxB.h
      const unionArea = boxAArea + boxBArea - interArea

      return interArea / unionArea
    }

    while (detections.length > 0) {
      const best = detections.shift()
      finalDetections.push(best)

      detections = detections.filter(det => calculateIoU(best, det) < iouThreshold)
    }

    return finalDetections
  }

  // ============================================================
  // 4Ô∏è‚É£ Detectar cada frame y dibujar en canvas
  // ============================================================
  const detectFrame = async (video, model, canvas, ctx) => {
    frameCount.current++
    const showLog = frameCount.current % 30 === 1

    try {
      const input = tf.tidy(() => {
        const tfImg = tf.browser.fromPixels(video)
        const resized = tf.image.resizeBilinear(tfImg, [640, 640])
        const normalized = resized.div(255.0)
        return normalized.expandDims(0)
      })

      const start = performance.now()
      const output = model.execute(input)
      const inference = performance.now() - start

      if (showLog) {
        console.log(`‚ö° Inferencia: ${inference.toFixed(1)}ms`)
      }

      const preds = Array.isArray(output) ? output[0] : output
      let decoded = await decodeYOLOOutput(preds, canvas.width, canvas.height, CONFIDENCE_THRESHOLD)

      // Filtrar por tama√±o m√≠nimo y coordenadas v√°lidas
      const beforeFilter = decoded.length
      decoded = decoded.filter(det => {
        if (det.x < 0 || det.y < 0) return false
        if (det.x + det.w > canvas.width || det.y + det.h > canvas.height) return false
        if (det.w < MIN_SIZE_PIXELS || det.h < MIN_SIZE_PIXELS) return false
        const aspectRatio = det.w / det.h
        if (aspectRatio < 0.3 || aspectRatio > 3) return false
        return true
      })

      if (showLog && beforeFilter !== decoded.length) {
        console.log(`   Filtradas (tama√±o m√≠n ${MIN_SIZE_PIXELS}px): ${beforeFilter} ‚Üí ${decoded.length}`)
      }

      // Aplicar NMS
      const beforeNMS = decoded.length
      decoded = applyNMS(decoded, NMS_IOU_THRESHOLD)

      if (showLog) {
        console.log(`‚úÖ Despu√©s de NMS: ${beforeNMS} ‚Üí ${decoded.length}`)
      }

      // üîÅ Limpiar canvas y dibujar video + cajas
      ctx.clearRect(0, 0, canvas.width, canvas.height)
      ctx.drawImage(video, 0, 0, canvas.width, canvas.height)

      let weaponDetected = false
      let knivesInFrame = 0
      let gunsInFrame = 0
      
      decoded.forEach((det) => {
        const { x, y, w, h, confidence, class: classId } = det
        weaponDetected = true
        
        // Clase 0: Cuchillo (Rojo), Clase 1: Pistola (Naranja)
        const isKnife = classId === 0
        const color = isKnife ? "#e74c3c" : "#ff8800"
        const fillColor = isKnife ? "rgba(231,76,60,0.9)" : "rgba(255,136,0,0.9)"
        const label = isKnife 
          ? `CUCHILLO ${(confidence * 100).toFixed(0)}%` 
          : `PISTOLA ${(confidence * 100).toFixed(0)}%`
        
        if (isKnife) knivesInFrame++
        else gunsInFrame++
        
        ctx.strokeStyle = color
        ctx.lineWidth = 3
        ctx.strokeRect(x, y, w, h)

        ctx.font = "bold 16px Arial"
        const textWidth = ctx.measureText(label).width
        ctx.fillStyle = fillColor
        ctx.fillRect(x, y > 20 ? y - 25 : y, textWidth + 10, 20)
        ctx.fillStyle = "#fff"
        ctx.fillText(label, x + 5, y > 20 ? y - 8 : y + 14)
      })

      // Actualizar estado
      if (weaponDetected) {
        setDangerLevel('danger')
        setDetections(decoded)
        
        let statusMsg = "‚ö†Ô∏è ARMA DETECTADA: "
        if (knivesInFrame > 0) statusMsg += `${knivesInFrame} cuchillo(s) `
        if (gunsInFrame > 0) statusMsg += `${gunsInFrame} pistola(s)`
        setStatus(statusMsg)

        // Capturar foto cada 2 segundos si est√° habilitado
        const now = Date.now()
        if (now - lastPhotoTime.current > 2000) {
          lastPhotoTime.current = now
          console.log(`üö® ¬°¬°¬°ARMA DETECTADA!!! - ${decoded.length} detecci√≥n(es) (${knivesInFrame} cuchillos, ${gunsInFrame} pistolas)`)
          
          if (autoSaveImages) {
            capturePhoto(canvas, decoded, knivesInFrame, gunsInFrame)
          }
          
          triggerAlert()
          
          if (knivesInFrame > 0) setTotalKnives(prev => prev + knivesInFrame)
          if (gunsInFrame > 0) setTotalGuns(prev => prev + gunsInFrame)
        }
      } else {
        setDangerLevel('safe')
        setDetections([])
        setStatus("Sin detecciones visibles")
      }

      tf.dispose([input, output])
    } catch (err) {
      console.error("‚ùå Error en detectFrame:", err)
    }

    // Repetir
    requestAnimationFrame(() => detectFrame(video, model, canvas, ctx))
  }

  // ============================================================
  // Funciones auxiliares
  // ============================================================
  const playBeep = () => {
    try {
      const audioContext = new (window.AudioContext || window.webkitAudioContext)()
      const oscillator = audioContext.createOscillator()
      const gainNode = audioContext.createGain()

      oscillator.connect(gainNode)
      gainNode.connect(audioContext.destination)

      oscillator.frequency.value = 800
      oscillator.type = 'sine'

      gainNode.gain.setValueAtTime(0.3, audioContext.currentTime)
      gainNode.gain.exponentialRampToValueAtTime(0.01, audioContext.currentTime + 0.5)

      oscillator.start(audioContext.currentTime)
      oscillator.stop(audioContext.currentTime + 0.5)

      console.log('‚úÖ Beep generado')
    } catch (err) {
      console.error('‚ùå Error al generar beep:', err)
    }
  }

  const triggerAlert = () => {
    setShowAlert(true)
    if (audioRef.current) {
      console.log('üîä Reproduciendo alerta...')
      audioRef.current.currentTime = 0
      audioRef.current.play()
        .then(() => console.log('‚úÖ Audio reproducido'))
        .catch(err => {
          console.warn('‚ö†Ô∏è Audio fall√≥:', err.message)
          playBeep()
        })
    } else {
      playBeep()
    }
    setTimeout(() => setShowAlert(false), 2500)
  }

  const capturePhoto = (canvas, detections, knives, guns) => {
    canvas.toBlob(blob => {
      if (!blob) return

      const timestamp = new Date()
      let prefix = 'arma'
      if (knives > 0 && guns === 0) prefix = 'cuchillo'
      else if (guns > 0 && knives === 0) prefix = 'pistola'
      else if (knives > 0 && guns > 0) prefix = 'multiple'
      
      const filename = `${prefix}_${timestamp.getTime()}.jpg`
      const url = URL.createObjectURL(blob)

      const photoData = {
        url,
        filename,
        timestamp: timestamp.toLocaleString(),
        detections: detections.length,
        knives,
        guns
      }

      setCapturedPhotos(prev => [photoData, ...prev].slice(0, 20))

      // Descargar autom√°ticamente
      const link = document.createElement('a')
      link.href = url
      link.download = filename
      link.click()

      console.log(`‚úÖ Foto guardada: ${filename}`)
    }, 'image/jpeg', 0.95)
  }

  const downloadAllPhotos = () => {
    console.log(`üì• Descargando ${capturedPhotos.length} fotos...`)
    capturedPhotos.forEach((photo, idx) => {
      setTimeout(() => {
        const link = document.createElement('a')
        link.href = photo.url
        link.download = photo.filename
        link.click()
      }, idx * 200)
    })
  }

  // ============================================================
  // 5Ô∏è‚É£ Bot√≥n iniciar detecci√≥n
  // ============================================================
  const startDetection = async () => {
    console.log("üé¨ ===== BOT√ìN 'INICIAR DETECCI√ìN' PRESIONADO =====")
    if (!modelRef.current) {
      alert("Primero carga el modelo")
      return
    }
    if (isDetecting) {
      alert("Ya se est√° detectando")
      return
    }

    setIsDetecting(true)
    await startCamera()

    setTimeout(() => {
      const video = videoRef.current
      const canvas = canvasRef.current
      const ctx = ctxRef.current
      const model = modelRef.current

      if (!video || !model) return

      if (video.readyState < 2) {
        console.warn("‚è≥ Esperando a que el video tenga datos...")
        video.addEventListener(
          "loadeddata",
          () => {
            console.log("üé• Video listo, iniciando detecci√≥n...")
            detectFrame(video, model, canvas, ctx)
          },
          { once: true }
        )
      } else {
        console.log("üé• Video listo inmediatamente, iniciando detecci√≥n...")
        detectFrame(video, model, canvas, ctx)
      }
    }, 300)
  }

  // ============================================================
  // Render
  // ============================================================
  return (
    <div className="app">
      <div className="container">
        <header className="header">
          <h1>üõ°Ô∏è Sistema de Detecci√≥n de Armas</h1>
          <p>YOLO11 + TensorFlow.js - Detecci√≥n de cuchillos y pistolas en tiempo real</p>
        </header>

        {showAlert && (
          <div className="alert-banner">
            <AlertTriangle size={28} />
            <span>‚ö†Ô∏è ¬°Arma detectada!</span>
          </div>
        )}

        {/* Configuraci√≥n actual */}
        <div className="card" style={{ marginBottom: '20px' }}>
          <h3 style={{ margin: '0 0 15px 0', color: '#333', fontSize: '1.2rem' }}>‚öôÔ∏è Configuraci√≥n Actual</h3>
          <div style={{
            display: 'grid',
            gridTemplateColumns: 'repeat(auto-fit, minmax(200px, 1fr))',
            gap: '10px',
            fontSize: '0.9rem'
          }}>
            <div><strong>Confianza m√≠nima:</strong> {CONFIDENCE_THRESHOLD * 100}%</div>
            <div><strong>Tama√±o m√≠nimo:</strong> {MIN_SIZE_PIXELS}px</div>
            <div><strong>NMS IoU:</strong> {NMS_IOU_THRESHOLD * 100}%</div>
          </div>
          <div style={{
            marginTop: '15px',
            padding: '10px',
            backgroundColor: '#f8f9fa',
            borderRadius: '8px',
            display: 'flex',
            alignItems: 'center',
            gap: '10px'
          }}>
            <label style={{
              display: 'flex',
              alignItems: 'center',
              gap: '8px',
              cursor: 'pointer',
              fontSize: '0.95rem',
              fontWeight: 'bold',
              color: '#333'
            }}>
              <input
                type="checkbox"
                checked={autoSaveImages}
                onChange={(e) => setAutoSaveImages(e.target.checked)}
                style={{
                  width: '18px',
                  height: '18px',
                  cursor: 'pointer'
                }}
              />
              üì∏ Guardar im√°genes autom√°ticamente al detectar armas
            </label>
          </div>
          <p style={{
            margin: '10px 0 0 0',
            fontSize: '0.8rem',
            color: '#666'
          }}>
            Para cambiar los umbrales, edita las constantes en las l√≠neas 22-24 del archivo App.jsx
          </p>
        </div>

        <div className="main-grid">
          <div className="card video-section">
            <h2 style={{ marginBottom: '20px', color: '#333', fontSize: '1.5rem' }}>üìπ Video</h2>
            <div style={{ position: "relative", display: "inline-block", width: '100%' }}>
              <video
                ref={videoRef}
                autoPlay
                muted
                playsInline
                style={{
                  width: "100%",
                  maxWidth: "640px",
                  height: "auto",
                  borderRadius: "10px",
                  border: "2px solid #555",
                  display: 'block',
                  margin: '0 auto'
                }}
              />

              <canvas
                ref={canvasRef}
                width="640"
                height="480"
                style={{
                  position: "absolute",
                  top: 0,
                  left: '50%',
                  transform: 'translateX(-50%)',
                  maxWidth: "640px",
                  width: "100%",
                  borderRadius: "10px",
                  pointerEvents: "none",
                }}
              />
            </div>

            <div style={{ marginTop: '20px', display: 'flex', gap: '10px', justifyContent: 'center', flexWrap: 'wrap' }}>
              <button
                onClick={loadModel}
                className="btn btn-primary"
              >
                üì¶ Cargar Modelo
              </button>
              <button
                onClick={startDetection}
                className="btn btn-primary"
                disabled={!modelRef.current || isDetecting}
              >
                üé¨ Iniciar Detecci√≥n
              </button>
            </div>
            <p style={{ textAlign: 'center', marginTop: '15px', fontSize: '1.1rem', color: '#333' }}>{status}</p>
          </div>

          <div className="card status-section">
            <h2>üìä Estado</h2>
            <TrafficLight dangerLevel={dangerLevel} />
            <DetectionStats
              dangerLevel={dangerLevel}
              totalKnives={totalKnives}
              totalGuns={totalGuns}
              detections={detections}
            />
          </div>
        </div>

        <div className="card reports-section">
          <h2>üìà Reportes</h2>
          <Charts
            detections={detections}
            detectionHistory={detectionHistory}
            totalKnives={totalKnives}
          />
        </div>

        {capturedPhotos.length > 0 && (
          <div className="card" style={{ marginTop: '20px' }}>
            <div style={{
              display: 'flex',
              justifyContent: 'space-between',
              alignItems: 'center',
              marginBottom: '15px'
            }}>
              <h2 style={{ margin: '0', color: '#333', fontSize: '1.5rem' }}>
                üì∏ Fotos Capturadas ({capturedPhotos.length})
              </h2>
              <button className="btn btn-primary" onClick={downloadAllPhotos}>
                <Download size={16} /> Descargar Todas
              </button>
            </div>
            <div style={{
              display: 'grid',
              gridTemplateColumns: 'repeat(auto-fill, minmax(200px, 1fr))',
              gap: '15px'
            }}>
              {capturedPhotos.map((photo, idx) => (
                <div key={idx} style={{
                  border: '2px solid #e74c3c',
                  borderRadius: '8px',
                  overflow: 'hidden',
                  backgroundColor: '#2c3e50'
                }}>
                  <img
                    src={photo.url}
                    alt={`Captura ${idx + 1}`}
                    style={{ width: '100%', display: 'block' }}
                  />
                  <div style={{
                    padding: '10px',
                    fontSize: '12px',
                    color: '#ecf0f1'
                  }}>
                    <div style={{ fontWeight: 'bold', marginBottom: '5px' }}>
                      {photo.knives > 0 && `üî™ ${photo.knives} cuchillo(s) `}
                      {photo.guns > 0 && `üî´ ${photo.guns} pistola(s)`}
                    </div>
                    <div>üïí {photo.timestamp}</div>
                    <div style={{
                      fontSize: '10px',
                      color: '#95a5a6',
                      marginTop: '5px'
                    }}>
                      {photo.filename}
                    </div>
                  </div>
                </div>
              ))}
            </div>
          </div>
        )}
      </div>
    </div>
  )
}

export default App
